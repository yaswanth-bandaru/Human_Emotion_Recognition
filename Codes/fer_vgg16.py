# -*- coding: utf-8 -*-
"""FER VGG16.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/132j6g0J5CK41fKnxCA8Kainu4tRjSmmh
"""

from google.colab import drive
drive.mount("/content/drive/",force_remount=True)

import os
os.getcwd()

import torch
import torch.nn as nn
import torchvision
import torch.optim as optim
from torch.optim import lr_scheduler
from torchvision.models import vgg16
from torch.utils.data import dataset
from torchvision import transforms
import pandas as pd
import os
import time
import copy
from PIL import Image
import numpy as np
import random
from skimage import io, transform
from sklearn.metrics import confusion_matrix
torch.cuda.empty_cache()
import matplotlib.pyplot as plt
import itertools
os.getcwd()

# Paths for data, model, an experiment name
DATA_ROOT = "/content/drive/My Drive/FER/Data/Images/"
MODEL_DIR = "/content/drive/My Drive/FER/models/"
exp_name = "exp"
SAVE_FOLDER = "/content/drive/My Drive/FER/Validation Results/"
MODEL_PATH = MODEL_DIR + exp_name
LEARNING_RATE = 0.01
NUM_EPOCHS = 80
device = "cuda"  #cpu

for _dir in ["/content/drive/My Drive/FER/Data/Images/", MODEL_PATH]:
    if not os.path.exists(_dir):
        os.makedirs(_dir)


def _process_row(row):
    """
    Process a single dataframe row, returns the argmax label
    :param row:
    :return:
    """
    return np.argmax(row)


class FERPlusDataset(dataset.Dataset):
    """
    Creats a PyTorch custom Dataset for batch iteration
    """
    def __init__(self, fer_data_dir, mode="train", transforms=None):
        self.fer_data_dir = fer_data_dir
        self.transforms = transforms
        self.mode = mode
        if self.mode == "train":
            self.img_dir = os.path.join(self.fer_data_dir, "FER2013Train")
        elif self.mode == "val":
            self.img_dir = os.path.join(self.fer_data_dir, "FER2013Valid")
        elif self.mode == "test":
            self.img_dir = os.path.join(self.fer_data_dir, "FER2013Test")
        self.label_file = os.path.join(self.img_dir, "label.csv")

        self.data_df = pd.read_csv(self.label_file, header=None)
        self.data_df.columns = [
            "img_name", "dims", "0", "1", "2", "3", "4", "5", "6", "7",
            "Unknown", "NF"
        ]

        # The arg-max label is the selected as the actual label for Majority Voting
        self.data_df['actual_label'] = self.data_df[[
            '0', '1', '2', '3', '4', '5', '6', '7'
        ]].apply(lambda x: _process_row(x), axis=1)

        # get all ilocs with actual label 0
        self.data_df.sort_values(by=['img_name'])

        if mode == "train":
            df_0 = sorted(self.data_df[
                self.data_df['actual_label'] == 0].index.values)

            # Sampling can be turned off otherwise selects only 40% of neutral ~ 4k images
            df_samples_0 = random.Random(1).sample(df_0,
                                                      int(len(df_0) * 0.6))
            df_1 = sorted(self.data_df[
                self.data_df['actual_label'] == 1].index.values)

            # Select only 50% of neutral ~ 4k images
            df_samples_1 = random.Random(1).sample(df_1,
                                                      int(len(df_1) * 0.5))
            self.data_df = self.data_df.drop(df_samples_0 + df_samples_1)

        self.image_file_names = self.data_df['img_name'].values

    def __getitem__(self, idx):
        img_file_name = self.image_file_names[idx]
        img_file = os.path.join(self.img_dir, img_file_name)
        img = Image.open(img_file).convert('RGB')
        img_class = self.get_class(img_file_name)

        if self.transforms is not None:
            img = self.transforms(img)

        return img, torch.tensor(img_class).to(torch.long)

    def get_class(self, file_name):
        """
        Returns the label for a corresponding file
        :param file_name: Image file name
        :return:
        """
        row_df = self.data_df[self.data_df["img_name"] ==
                                    file_name]
        init_val = -1
        init_idx = -1
        for x in range(2, 10):
            max_val = max(init_val, row_df.iloc[0].values[x])
            if max_val > init_val:
                init_val = max_val
                init_idx = int(
                    x - 2
                )  # Labels indices must start at 0, -2 if all else -4!!!!!!
        return init_idx

    def __len__(self):
        return len(self.image_file_names)


if __name__ == '__main__':
# Create train, val and test transforms
    train_transform = transforms.Compose([
        transforms.RandomAffine(degrees=10),
        transforms.Resize(224),
        transforms.ToTensor(),
        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
    ])

    val_transform = transforms.Compose([
        transforms.Resize(224),
        transforms.ToTensor(),
        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
    ])

    test_transform = transforms.Compose([
        transforms.Resize(224),
        transforms.ToTensor(),
        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
    ])

    train_ds = FERPlusDataset("/content/drive/My Drive/FER/Data/Images/", mode="train", transforms=train_transform)
    val_ds = FERPlusDataset("/content/drive/My Drive/FER/Data/Images/", mode="val", transforms=val_transform)
    test_ds = FERPlusDataset("/content/drive/My Drive/FER/Data/Images/", mode="test", transforms=test_transform)

    dataloaders = {
        'train':
        torch.utils.data.DataLoader(train_ds,
                                    batch_size=128,
                                    shuffle=True,
                                    num_workers=8),
        'val':
        torch.utils.data.DataLoader(val_ds,
                                    batch_size=128,
                                    shuffle=True,
                                    num_workers=8),
        'test':
        torch.utils.data.DataLoader(test_ds,
                                    batch_size=128,
                                    shuffle=True,
                                    num_workers=8)
    }
    
    # Visualisation

    def plot_confusion_matrix(cm,epoch, classes,
                              normalize=False,
                              title='Confusion matrix',
                              cmap=plt.cm.Blues):

        plt.imshow(cm, interpolation='nearest', cmap=cmap)
        plt.title(title)
        plt.colorbar()
        tick_marks = np.arange(len(classes))
        plt.xticks(tick_marks, classes, rotation=90)
        plt.yticks(tick_marks, classes)

        if normalize:
            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

        thresh = cm.max() / 2.
        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
            plt.text(j, i, cm[i, j],
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")

        plt.tight_layout()
        plt.ylabel('True label')
        plt.xlabel('Predicted label')
        save_folder = "/content/drive/My Drive/FER/Validation Results/" + str(epoch)
        if not os.path.exists(save_folder):
            os.makedirs(save_folder)
        plt.savefig(save_folder + "/")
        plt.close()
        plt.clf()

    def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
        since = time.time()

        best_model_wts = copy.deepcopy(model.state_dict())
        best_acc = 0.0
        phases = ["train", "val"]

        train_acc = []
        test_acc = []

        for epoch in range(num_epochs):
            print('Epoch {}/{}'.format(epoch, num_epochs - 1))
            print('-' * 10)

            for phase in phases:
                if phase == 'train':
                    model.train()  # Set model to training mode
                else:
                    model.eval()  # Set model to evaluate mode

                running_loss = 0.0
                running_corrects = 0


                for idx, data in enumerate(dataloaders[phase]):
                    inputs, labels = data
                    inputs = inputs.to(device)
                    labels = labels.to(device)

                    # zero the parameter gradients
                    optimizer.zero_grad()

                    outputs = model(inputs)
                    loss = criterion(outputs, labels)
                    _, preds = torch.max(outputs, 1)
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                    # statistics
                    running_loss += loss.item()
                    running_corrects += torch.sum(preds == labels.data)

                if phase == 'train':
                    scheduler.step()

                epoch_loss = running_loss / len(dataloaders[phase].dataset)
                epoch_acc = running_corrects.double() / len(
                    dataloaders[phase].dataset)
                
                if phase == 'train':
                  train_acc.append(epoch_acc)
                print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss,
                                                           epoch_acc))

                # deep copy the model
                if phase == 'val' and epoch_acc > best_acc:
                    best_acc = epoch_acc
                    best_model_wts = copy.deepcopy(model.state_dict())

            if epoch != 0 and epoch % 1 == 0:
                # checkpoint model
                torch.save(model,
                           os.path.join(MODEL_PATH, f"model_{str(epoch)}.pth"))
                print("Running test mode")
                running_loss_test = 0
                running_corrects_test = 0

                running_preds = []
                running_labels = []

                for idx, data in enumerate(dataloaders["test"]):
                    test_inputs, test_labels = data
                    test_inputs = test_inputs.to(device)
                    test_labels = test_labels.to(device)
                    outputs = model(test_inputs)
                    loss = criterion(outputs, test_labels)
                    _, preds = torch.max(outputs, 1)

                    running_preds.append(preds.squeeze(0).cpu().numpy())
                    running_labels.append(test_labels.squeeze(0).cpu().numpy())

                    running_loss_test += loss.item()
                    running_corrects_test += torch.sum(preds == test_labels.data)

                epoch_loss = running_loss_test / len(dataloaders["test"].dataset)
                epoch_acc = running_corrects_test.double() / len(
                    dataloaders["test"].dataset)
                print('Test Loss: {:.4f} Acc: {:.4f}'.format(
                    epoch_loss, epoch_acc))
                test_acc.append(epoch_acc)
                
                cmat = confusion_matrix(
                    [label for batch in running_labels for label in batch],
                    [label for batch in running_preds for label in batch])
                print(f"Test confusion matrix: \n{cmat}")
                plot_confusion_matrix(cmat,epoch, classes = ['neutral','happiness','surprise','sadness','anger'])

        time_elapsed = time.time() - since
        print('Training complete in {:.0f}m {:.0f}s'.format(
            time_elapsed // 60, time_elapsed % 60))
        print('Best val Acc: {:4f}'.format(best_acc))

        # load best model weights
        model.load_state_dict(best_model_wts)
        acc_folder = "/content/drive/My Drive/FER/Accuracy Plot/train_plot.png"
        plt.figure(figsize=(10,5))
        plt.title("Training and test Loss")
        plt.plot(train_acc,label="train")
        plt.plot(test_acc,label="test")
        plt.xlabel("Epoch")
        plt.ylabel("Accuracy")
        plt.legend()
        plt.show()
        plt.savefig(acc_folder)
        plt.savefig("train_plot.png")
        return model,train_acc,test_acc


    # PRE TRAINED
    model = vgg16(pretrained=True)
    num_ftrs = model.classifier[3].out_features

    model.classifier = nn.Sequential(nn.Linear(5 * 5 * 512, 1024),
                                     nn.ReLU(),
                                     nn.Dropout(0.25),
                                     nn.Linear(1024, 1024),
                                     nn.ReLU(),
                                     nn.Dropout(0.25),
                                     nn.Linear(1024, 5))

    for param in model.features.parameters():
        param.requires_grad = False

    model = model.to(device)

    criterion = nn.CrossEntropyLoss()

    # # Observe that all parameters are being optimized
    optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.8)

    # # Decay LR by a factor of 0.1 every 20 epochs
    lr = lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.1)

    model,train_acc,test_acc = train_model(model,
                        criterion,
                        optimizer,
                        lr,
                        num_epochs=NUM_EPOCHS)
    

    # Save model
    torch.save(model, os.path.join(MODEL_PATH, "model.pth"))

pd.read_csv('/content/drive/My Drive/FER/Data/Images/FER2013Train/label.csv')

